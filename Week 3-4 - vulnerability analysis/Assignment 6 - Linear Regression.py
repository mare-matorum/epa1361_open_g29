
import numpy as np
import matplotlib.pyplot as plt
import pandas as pd
import seaborn as sns
import statsmodels.api as sm
from patsy.highlevel import dmatrices

from ema_workbench import (Model, RealParameter, TimeSeriesOutcome, ScalarOutcome, perform_experiments, ema_logging, SequentialEvaluator)
from ema_workbench.analysis import plotting, plotting_util
from ema_workbench.em_framework.evaluators import LHS, SOBOL, MORRIS

from ema_workbench.analysis import feature_scoring
from ema_workbench.analysis.scenario_discovery_util import RuleInductionType
from ema_workbench.em_framework.salib_samplers import get_SALib_problem
from SALib.analyze import sobol


def pred_prey(prey_birth_rate=0.025, predation_rate=0.0015, predator_efficiency=0.002,
             predator_loss_rate=0.06, initial_prey=50, initial_predators=20, dt=0.25, 
             final_time=365, reps=1):

    #Initial values
    predators = np.zeros((reps, int(final_time/dt)+1))
    prey = np.zeros((reps, int(final_time/dt)+1))
    sim_time = np.zeros((reps, int(final_time/dt)+1))
    
    for r in range(reps):

        predators[r,0] = initial_predators
        prey[r,0] = initial_prey

    #Calculate the time series
    for t in range(0, sim_time.shape[1]-1):

        dx = (prey_birth_rate*prey[r,t]) - (predation_rate*prey[r,t]*predators[r,t])
        dy = (predator_efficiency*predators[r,t]*prey[r,t]) - (predator_loss_rate*predators[r,t])

        prey[r,t+1] = max(prey[r,t] + dx*dt, 0)
        predators[r,t+1] = max(predators[r,t] + dy*dt, 0)
        sim_time[r,t+1] = (t+1)*dt
    
    #Return outcomes
    return {'TIME':sim_time,
            'predators':predators,
            'prey':prey}

# Instantiate Python model
modelPython = Model('PredPreyPython', function=pred_prey) # instantiate the model


def generate_regression(X, y):
    # Add column of ones to the end of the dependent variable matrix
    X = sm.add_constant(X, prepend=False)

    # Fit and summarize OLS model
    mod = sm.OLS(y, X)
    res = mod.fit()
    print(res.summary())

def generate_regression_single(x, y):
    # Add column of ones to the end of the dependent variable matrix
    x = sm.add_constant(x, prepend=False)

    # Fit and summarize OLS model
    mod = sm.OLS(y, x)
    res = mod.fit()
    print(res.summary())

# Function expects an instance of a model and plots it
def plot_lotka_volterra(model_instance):

    model_instance.uncertainties = [RealParameter ('prey_birth_rate', 0.015, 0.035),
                                 RealParameter ('predation_rate', 0.0005, 0.003),
                                 RealParameter ('predator_efficiency', 0.001, 0.004),
                                 RealParameter ('predator_loss_rate', 0.04, 0.08)
                                 ]

    model_instance.outcomes = [TimeSeriesOutcome('TIME'),
                            TimeSeriesOutcome('predators'),
                            TimeSeriesOutcome('prey')]

    with SequentialEvaluator(model_instance) as evaluator:
        sa_results = evaluator.perform_experiments(scenarios=50, uncertainty_sampling=LHS)

    experiments, outcomes = sa_results

    # Squeeze outcomes
    outcomes_squeezed = {}

    for key in outcomes:
        outcomes_squeezed[key] = np.squeeze(outcomes[key])

    # Store final values of prey outcome
    prey_final = []
    prey_mean = []
    prey_std = []

    # Iterate through rows of outcome numpy array (experiments) to calculate indicators
    for experiment_row in outcomes_squeezed["prey"]:
        prey_final.append(experiment_row[-1]) # Get last element
        prey_mean.append(np.mean(experiment_row))
        prey_std.append(np.std(experiment_row))

    # Collect indicators in dictionary to calculate regression for each of them
    indicators = {'prey_final':prey_final, 'prey_mean':prey_mean, 'prey_std':prey_std}

    # Calculate regression to investigate relationship between uncertainties and final number of preys after one year, the mean value of preys, and the standard deviation of preys
    for indicator_key in indicators.keys():
        generate_regression_single(experiments["prey_birth_rate"], indicators[indicator_key])
        generate_regression_single(experiments["predation_rate"], indicators[indicator_key])
        generate_regression_single(experiments["predator_efficiency"], indicators[indicator_key])
        generate_regression_single(experiments["predator_loss_rate"], indicators[indicator_key])
        
    # Select uncertainties that were applied in every experiment
    # uncertainties_experiments = experiments[["prey_birth_rate", "predation_rate", "predator_efficiency", "predator_loss_rate"]]

    # generate_regression_single(experiments["prey_birth_rate"], prey_final)

    #generate_regression(uncertainties_experiments, prey_final)
    #generate_regression(uncertainties_experiments, prey_mean)
    #generate_regression(uncertainties_experiments, prey_std)

    #for outcome_key in outcomes_squeezed.keys():
    #   if outcome_key != 'TIME':
            # Fetch numpy array from dictionary, and calculate average over every single column (average at every point of time)
            # Plot using workbench
            #plotting.lines(experiments, outcomes_squeezed, outcomes_to_show=outcome_key, density=plotting_util.Density.HIST)

    return prey_final, prey_mean, prey_std

    # problem = get_SALib_problem(model_instance.uncertainties)
    # Si = sobol.analyze(problem, outcomes['prey'], calc_second_order=True, print_to_console=False)
    #
    # scores_filtered = {k:Si[k] for k in ['ST','ST_conf','S1','S1_conf']}
    # Si_df = pd.DataFrame(scores_filtered, index=problem['names'])
    #
    # sns.set_style('white')
    # fig, ax = plt.subplots(1)
    #
    # indices = Si_df[['S1','ST']]
    # err = Si_df[['S1_conf','ST_conf']]
    #
    # indices.plot.bar(yerr=err.values.T,ax=ax)
    # fig.set_size_inches(8,6)
    # fig.subplots_adjust(bottom=0.3)
    # plt.show()

    # Thoughts for the error calculation:
    # For every key (predators, prey), at every time step, calculate the average over all scenarios
    # Then, we have a list of averages for all time steps
    # Then, calculate the difference between the list from Excel and the list from Python.
    # Then, find the maximum deviation. This is our maximum absolute error.



prey_final, prey_mean, prey_std = plot_lotka_volterra(modelPython)

print(prey_final)
print(prey_mean)
print(prey_std)
